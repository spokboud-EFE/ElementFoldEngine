# ElementFold ¬∑ experience/steering.py
# The SteeringController turns *intent text* into a compact control vector:
#   v ‚àà ‚Ñù‚Å∏ = [Œ≤, Œ≥, clamp, style‚ÇÖ]
# where:
#   ‚Ä¢ Œ≤ (beta)    ‚Äî gate exposure strength (how strongly FGN exposes novelty),
#   ‚Ä¢ Œ≥ (gamma)   ‚Äî normalization damping (how hard FGN calms energy),
#   ‚Ä¢ clamp (‚õî)  ‚Äî gate cap (how deep negative gate values can go before we clip),
#   ‚Ä¢ style‚ÇÖ      ‚Äî free style slots adapters can use (e.g., tone, tempo, sharpness, etc.).
#
# The controller is deliberately small and fast:
#   tokenizer ‚Üí ids ‚Üí embedding ‚Üí mean‚Äëpool ‚Üí 2‚Äëlayer MLP ‚Üí ‚Ñù‚Å∏ control.
# We keep it trainable (see steering_train.py), but also useful ‚Äúas is.‚Äù

import torch, torch.nn as nn                              # ‚ú¥ tensors ‚Ä¢ modules
from ..tokenizer import SimpleTokenizer                   # ‚ú¥ tiny tokenizer (vocab‚âà256)


class SteeringController(nn.Module):                      # üéö intent ‚Üí (Œ≤, Œ≥, ‚õî, style‚ÇÖ)
    def __init__(self, delta: float = 0.030908106561043047):
        """
        Args:
            delta: Œ¥‚ãÜ coherence unit (cached here so downstream consumers can read it if needed).
        """
        super().__init__()                                # ‚ú¥ standard Module init
        self.delta = float(delta)                         # Œ¥‚ãÜ cached as a plain float

        # ‚Äî Embedding ‚Äî
        # We keep a tiny vocabulary (256) in sync with SimpleTokenizer; each token maps to ‚Ñù‚Å∂‚Å¥.
        self.emb = nn.Embedding(256, 64)                  # E: vocab256 ‚Üí ‚Ñù‚Å∂‚Å¥

        # ‚Äî Head (MLP) ‚Äî
        # A small 2‚Äëlayer perceptron to turn the pooled embedding into ‚Ñù‚Å∏ (Œ≤, Œ≥, ‚õî, style‚ÇÖ).
        self.fc = nn.Sequential(                          # Œ†: ‚Ñù‚Å∂‚Å¥ ‚Üí ‚Ñù‚Å∏
            nn.Linear(64, 64),                            # affine ‚Üí ‚Ñù‚Å∂‚Å¥
            nn.ReLU(),                                    # nonlinearity (stable, simple)
            nn.Linear(64, 8),                             # affine ‚Üí ‚Ñù‚Å∏
        )

        # We do not fix output ranges here; instead we offer a helper (to_params)
        # that maps raw outputs into meaningful ranges (Œ≤‚àà[0.5,2.0], Œ≥‚àà[0,0.9], ‚õî‚àà[1,10]).

    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
    # Core forward (kept trainable for fine‚Äëtuning)
    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
    def forward(self, s: str) -> torch.Tensor:
        """
        Turn a text prompt into a raw control vector v ‚àà ‚Ñù‚Å∏.

        Steps:
          1) tokenize the prompt (list[int]),
          2) embed tokens (1,L,64),
          3) mean‚Äëpool across L ‚Üí (1,64),
          4) MLP ‚Üí (1,8),
          5) squeeze batch ‚Üí (8,).

        Returns:
            torch.Tensor of shape (8,), dtype matches module parameters (float32 by default).
        """
        tok = SimpleTokenizer()                           # ‚ú¥ instantiate tokenizer
        ids = tok.encode(s)                               # ids: list[int], may be empty for empty input
        if len(ids) == 0:                                 # guard: ensure at least one token
            ids = [0]                                     # use a neutral token id 0

        # Build a tensor on the same device as our parameters to avoid device mismatches.
        dev = self.emb.weight.device                      # üñ• where the module lives (cpu/cuda)
        x = torch.tensor(ids, dtype=torch.long, device=dev).unsqueeze(0)  # (1,L) batchify ids

        e = self.emb(x).mean(dim=1)                       # ‚ü≤ pooled embedding (1,64) via mean over sequence length
        v = self.fc(e).squeeze(0)                         # ‚Ñù‚Å∏ = [Œ≤ÃÇ, Œ≥ÃÇ, ‚õîÃÇ, style‚ÇÖ] (raw, unconstrained)
        return v                                          # ‚ú¥ raw controls (let caller map to ranges)

    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
    # Helpers: map raw vector ‚Üí meaningful ranges
    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
    @staticmethod
    def to_params(v: torch.Tensor) -> dict:
        """
        Convert a raw ‚Ñù‚Å∏ vector (as returned by forward) into interpretable parameters
        with ranges aligned to the Supervisor‚Äôs defaults:

            Œ≤   ‚àà [0.5, 2.0]
            Œ≥   ‚àà [0.0, 0.9]
            ‚õî  ‚àà [1.0, 10.0]
            style ‚àà ‚Ñù‚Åµ  (left unconstrained; adapters interpret it)

        Returns:
            {'beta': float, 'gamma': float, 'clamp': float, 'style': torch.Tensor(5,)}
        """
        v = v.to(torch.float32)                           # ensure stable float math
        beta  = (v[0].sigmoid().item() + 0.5)            # map (‚àí‚àû,‚àû) ‚Üí (0,1) ‚Üí (0.5,1.5) then +0.5 ‚Üí (0.5,2.0)
        gamma = (v[1].sigmoid().item() * 0.9)            # (0,1) scaled into [0,0.9]
        clamp = (v[2].sigmoid().item() * 9.0 + 1.0)      # (0,1) ‚Üí [1,10]
        style = v[3:8].detach()                           # pass style‚ÇÖ as a small free vector for adapters
        return {"beta": beta, "gamma": gamma, "clamp": clamp, "style": style}

    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
    # Convenience factories (untrained vs. checkpoint)
    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
    @classmethod
    def load_default(cls, delta: float = 0.030908106561043047) -> "SteeringController":
        """
        Factory: create a fresh, untrained controller.
        This is useful for prototyping; training lives in steering_train.py.
        """
        return cls(delta)                                  # ‚â° fresh controller (random weights)

    @classmethod
    def load(cls, path: str, delta: float = 0.030908106561043047) -> "SteeringController":
        """
        Factory: load weights from a state_dict checkpoint at `path`.
        The controller is returned in eval mode.
        """
        m = cls(delta)                                     # ‚ú¥ construct
        sd = torch.load(path, map_location="cpu")          # üß± read state dict (portable)
        m.load_state_dict(sd)                              # ‚ü≤ load weights
        m.eval()                                           # ‚â° evaluation mode (safer defaults)
        return m                                           # ‚ú¥ ready controller

    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
    # Optional: apply controls to a model directly
    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
    def apply_to_model(self, model, s: str | None = None, v: torch.Tensor | None = None) -> dict:
        """
        Convenience: produce controls (from a prompt `s` or raw vector `v`) and push them
        into any model that implements `.apply_control(beta=?, gamma=?, clamp=?)`.
        Returns the parameter dict actually applied.

        Usage:
            ctrl = SteeringController.load_default()
            applied = ctrl.apply_to_model(model, s="calm, softer, lower gain")
        """
        if v is None:
            if s is None:
                raise ValueError("either `s` (prompt) or `v` (raw ‚Ñù‚Å∏ vector) must be provided")
            v = self.forward(s)                             # ‚Ü¶ raw ‚Ñù‚Å∏ from text
        params = self.to_params(v)                          # ‚Ü¶ map into meaningful ranges
        if hasattr(model, "apply_control"):                 # only apply if the model supports it
            model.apply_control(beta=params["beta"], gamma=params["gamma"], clamp=params["clamp"])
        return params                                       # useful for logging/UX
