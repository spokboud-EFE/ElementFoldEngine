# ElementFold ¬∑ experience/steering.py
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# The SteeringController turns *intent text* into a compact control vector:
#   v ‚àà ‚Ñù‚Å∏ = [Œ≤, Œ≥, ‚õî, style‚ÇÖ]
#
# Meanings:
#   ‚Ä¢ Œ≤ (beta)    ‚Äî gate exposure (how strongly FGN exposes novelty),
#   ‚Ä¢ Œ≥ (gamma)   ‚Äî normalization damping (how hard FGN calms energy),
#   ‚Ä¢ ‚õî (clamp)  ‚Äî gate cap (how deep negative gate values can go before clipping),
#   ‚Ä¢ style‚ÇÖ      ‚Äî five free ‚Äústyle‚Äù scalars adapters can interpret (tone, tempo, etc.).
#
# Design goals:
#   ‚Ä¢ Minimal & fast: tokenizer ‚Üí ids ‚Üí embedding ‚Üí mean‚Äëpool ‚Üí 2‚Äëlayer MLP ‚Üí ‚Ñù‚Å∏.
#   ‚Ä¢ Trainable: see steering_train.py; defaults work out‚Äëof‚Äëthe‚Äëbox.
#   ‚Ä¢ Safe ranges: a helper maps raw outputs into Supervisor‚Äëaligned bounds.
#
# Contract with Studio:
#   ctrl = SteeringController.load_default(cfg.delta)
#   v    = ctrl("gentle, coherent")     # ‚Üí ‚Ñù‚Å∏
#   p    = SteeringController.to_params(v)  # ‚Üí {'beta','gamma','clamp','style'}
#
from __future__ import annotations

from typing import Dict
import torch
import torch.nn as nn

from ..tokenizer import SimpleTokenizer


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Small helpers
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def _sigmoid_range(x: torch.Tensor, lo: float, hi: float) -> torch.Tensor:
    """
    Map ‚Ñù ‚Üí (lo, hi) smoothly via œÉ. Works element‚Äëwise and is differentiable.
    """
    return torch.sigmoid(x) * (hi - lo) + lo


class SteeringController(nn.Module):  # üéö intent ‚Üí (Œ≤, Œ≥, ‚õî, style‚ÇÖ)
    """
    A tiny intent‚Üícontrol head. Forward returns a raw ‚Ñù‚Å∏ vector; use .to_params()
    to map into meaningful ranges.

    Notes:
      ‚Ä¢ Œ¥‚ãÜ (delta) is cached for convenience‚Äîsome adapters may want to read it.
      ‚Ä¢ Tokenizer is intentionally tiny (vocab‚âà256); mean‚Äëpooling is robust for short prompts.
    """

    # For very long prompts, we can cap length to keep latency predictable.
    MAX_TOKENS: int = 512

    def __init__(self, delta: float = 0.030908106561043047):
        super().__init__()
        self.delta = float(delta)               # Œ¥‚ãÜ cached (read‚Äëonly convenience)

        # ‚Äî Embedding ‚Äî
        # Keep in sync with SimpleTokenizer (vocab size = 256). Each token ‚Üí ‚Ñù‚Å∂‚Å¥.
        self.emb = nn.Embedding(256, 64)

        # ‚Äî Head (MLP) ‚Äî
        # A tiny two‚Äëlayer perceptron: ‚Ñù‚Å∂‚Å¥ ‚Üí ‚Ñù‚Å∏ = [Œ≤ÃÇ, Œ≥ÃÇ, ‚õîÃÇ, style‚ÇÖ].
        self.fc = nn.Sequential(
            nn.Linear(64, 64),
            nn.ReLU(),
            nn.Linear(64, 8),
        )

    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
    # Core forward (kept trainable for fine‚Äëtuning)
    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
    def forward(self, s: str) -> torch.Tensor:
        """
        Turn a text prompt into a raw control vector v ‚àà ‚Ñù‚Å∏.

        Steps:
          1) tokenize prompt ‚Üí ids,
          2) embed ‚Üí (1, L, 64),
          3) mean‚Äëpool across tokens ‚Üí (1, 64),
          4) MLP ‚Üí (1, 8),
          5) squeeze batch ‚Üí (8,).

        Returns:
            torch.Tensor shape (8,), dtype float32 by default.
        """
        tok = SimpleTokenizer()
        ids = tok.encode(s)

        # Guard: allow empty input, cap extremely long inputs to bound latency.
        if not ids:
            ids = [0]
        if len(ids) > self.MAX_TOKENS:
            ids = ids[: self.MAX_TOKENS]

        dev = self.emb.weight.device
        x = torch.tensor(ids, dtype=torch.long, device=dev).unsqueeze(0)  # (1, L)
        e = self.emb(x).mean(dim=1)                                       # (1, 64)
        v = self.fc(e).squeeze(0)                                         # (8,)
        return v

    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
    # Helpers: map raw vector ‚Üí meaningful ranges
    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
    @staticmethod
    def to_params(v: torch.Tensor) -> Dict[str, object]:
        """
        Convert a raw ‚Ñù‚Å∏ vector (as returned by forward) into interpretable parameters
        with ranges aligned to the Supervisor‚Äôs defaults:

            Œ≤    ‚àà [0.5, 2.0]
            Œ≥    ‚àà [0.0, 0.9]
            ‚õî   ‚àà [1.0, 10.0]
            style ‚àà ‚Ñù‚Åµ  (left unconstrained; adapters can interpret freely)

        Returns:
            {'beta': float, 'gamma': float, 'clamp': float, 'style': torch.Tensor(5,)}
        """
        # Ensure predictable dtype/device; drop grad to avoid leaking graphs into the UI.
        with torch.no_grad():
            v = v.to(dtype=torch.float32)

            # Map first three controls into safe physical ranges via œÉ.
            beta  = _sigmoid_range(v[0], 0.5, 2.0).item()
            gamma = _sigmoid_range(v[1], 0.0, 0.9).item()
            clamp = _sigmoid_range(v[2], 1.0, 10.0).item()

            # Style left unconstrained for adapters (they may tanh/normalize if desired).
            style = v[3:8].detach()

        return {"beta": beta, "gamma": gamma, "clamp": clamp, "style": style}

    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
    # Convenience factories (untrained vs. checkpoint)
    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
    @classmethod
    def load_default(cls, delta: float = 0.030908106561043047) -> "SteeringController":
        """
        Create a fresh, untrained controller (useful for prototyping).
        Training lives in steering_train.py.
        """
        return cls(delta)

    @classmethod
    def load(cls, path: str, delta: float = 0.030908106561043047) -> "SteeringController":
        """
        Load weights from a state_dict checkpoint at `path`. Returns the controller in eval mode.
        """
        m = cls(delta)
        sd = torch.load(path, map_location="cpu")
        m.load_state_dict(sd)
        m.eval()
        return m

    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
    # Optional: apply controls to a model directly
    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
    def apply_to_model(self, model, s: str | None = None, v: torch.Tensor | None = None) -> Dict[str, object]:
        """
        Produce controls (from a prompt `s` or raw vector `v`) and push them
        into any model that implements `.apply_control(beta=?, gamma=?, clamp=?)`.

        Returns:
            The parameter dict actually applied (useful for logging/UX).
        """
        if v is None:
            if s is None:
                raise ValueError("either `s` (prompt) or `v` (raw ‚Ñù‚Å∏ vector) must be provided")
            v = self.forward(s)
        params = self.to_params(v)
        if hasattr(model, "apply_control"):
            model.apply_control(beta=params["beta"], gamma=params["gamma"], clamp=params["clamp"])
        return params
