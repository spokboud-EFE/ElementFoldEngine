# elementfold/rung_controller.py
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# RungController â€” coherenceâ€‘aware control shim for ElementFold
#
# Goals
#   â€¢ Provide a tiny, safe controller that adds rungâ€‘aware nudges on top of a
#     higherâ€‘level Supervisor (Î², Î³, and â›” clamp), without hijacking policy.
#   â€¢ Export RungIntent used by training/loss shaping (STABILIZE / HOLD / SEEK).
#   â€¢ Offer a *compatible* API with optional â€œrelative stepsâ€ for legacy code:
#       set_intent("step_up", steps=2)   # â† works
#       set_intent("step_down", steps=1) # â† works
#
# Key ideas (plain language, with a little math)
#   â€¢ ElementFoldâ€™s hidden coordinate X forms discrete â€œrungsâ€ spaced by Î´â‹†.
#   â€¢ The controller watches telemetry (pÂ½ ~ â€œbarrier probabilityâ€, Îº ~ â€œlock
#     confidenceâ€, x_mean ~ â€œwhere X sitsâ€), then blends tiny overrides:
#         Î² (responsiveness), Î³ (damping), and â›” (magnitude clamp).
#   â€¢ A gentle FSM guides barrier crossing:
#         LOCKED â†’ MID (lean) â†’ CROSSING (over the ridge) â†’ CAPTURE (reâ€‘lock).
#
# Silent relaxation awareness (diffusion/decay in small, safe doses)
#   â€¢ If the runtime also reports relaxation signals â€” folds ð”‰ (or F), share rate Î·,
#     lettingâ€‘go Î», smoothing D â€” we distill them into a calmness score âˆˆ [0,1].
#     More calm â‡’ slightly less Î², slightly higher Î³, slightly softer â›”.
#   â€¢ During CROSSING/MID we trim the crossâ€‘override weight a touch as calm â†‘.
#     During HOLD/CAPTURE we nudge the holdâ€‘override weight a touch as calm â†‘.
#   â€¢ If none of these signals are present, behavior is identical to before.
#
# Implementation notes
#   â€¢ Pure stdlib; no heavy deps. Designed to be easy to read & test.
#   â€¢ Backâ€‘compat: accepts step_up/step_down intents with a `steps=` kwarg.
#   â€¢ If x_mean is missing, decisions degrade gracefully using pÂ½ and Îº.
#
# MITâ€‘style tiny utility. Â© 2025 ElementFold authors.

from __future__ import annotations

from dataclasses import dataclass, asdict
from enum import Enum
from typing import Optional, Dict, Literal, Union, Any

# Phase of the finiteâ€‘state machine while seeking
ModePhase = Literal["LOCKED", "MID", "CROSSING", "CAPTURE"]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Public: RungIntent (also referenced by training code / loss shaping)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class RungIntent(str, Enum):
    """Highâ€‘level policy around rungs used by training and control."""
    STABILIZE = "stabilize"  # keep within acceptance band; default safe mode
    HOLD      = "hold"       # actively center & damp on the nearest rung
    SEEK      = "seek"       # walk across barriers toward a target rung (k_target)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Tuning (gentle defaults that behave well in smoke tests)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class RungTuning:
    """
    All values are dimensionless. â›” = clamp on auxiliary updates.

    ðŸ§­ Intuition:
      â€¢ Higher Î³ near the barrier discourages â€œteeteringâ€.
      â€¢ Slight Î² boost when crossing encourages decisive movement.
      â€¢ Blends are small (â‰¤ 0.5), because Supervisor stays in charge.

    Relaxationâ€‘aware microâ€‘modulation:
      â€¢ calmness âˆˆ [0,1] softly reduces Î², softly raises Î³, softly lowers â›”.
      â€¢ Crossâ€‘phase blend (MID/CROSSING) is trimmed a bit as calm â†‘.
      â€¢ Holdâ€‘phase blend (LOCKED/CAPTURE) is nudged up a bit as calm â†‘.
    """
    # Acceptance band halfâ€‘width; default â‰ˆ Î´â‹†/6
    epsilon_scale: float = 1 / 6

    # State machine thresholds (fallbacks if tele['p_half'] unavailable)
    p_half_target: float = 0.55     # above 0.5 â†’ very likely â€œover the ridgeâ€
    p_half_lock: float   = 0.12     # well under this â†’ â€œlockedâ€ on a rung

    # Dwell (ticks) for decisions; short for training, can be longer in prod
    dwell_mid: int  = 3            # linger at MID a few ticks before crossing
    dwell_lock: int = 3            # linger at CAPTURE before declaring lock

    # Override magnitudes (targets we blend toward)
    beta_boost: float    = 2.0      # nimble while crossing
    beta_hold: float     = 1.2      # modest Î² when holding
    gamma_damp_lo: float = 0.05     # low damping while crossing
    gamma_damp_hi: float = 0.60     # higher damping when locking/capturing
    clamp_safe: float    = 5.0      # safe â›” during guidance

    # Blend weights (0..1): 0=keep Supervisor, 1=use target
    blend_cross: float   = 0.50
    blend_hold: float    = 0.35
    blend_capture: float = 0.45

    # Hard rails: we never send wild values to the model
    beta_min: float  = 0.5
    beta_max: float  = 3.0
    gamma_min: float = 0.0
    gamma_max: float = 1.5
    clamp_min: float = 1.0
    clamp_max: float = 12.0

    # â”€â”€ Relaxation (diffusion/decay) modulation knobs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Squash scales for turning raw signals into â€œhow calm does this look?â€
    relax_F_scale: float      = 1.0    # folds ð”‰ scale
    relax_eta_scale: float    = 0.02   # shareâ€‘rate Î· scale (smaller â‡’ less calm)
    relax_lambda_scale: float = 0.10   # lettingâ€‘go Î» scale
    relax_D_scale: float      = 0.10   # smoothing D scale

    # How much to modulate at full calmness
    relax_beta_soften: float        = 0.10  # up to âˆ’10% on Î²
    relax_gamma_boost: float        = 0.15  # up to +0.15 on Î³ (additive)
    relax_clamp_soften: float       = 0.25  # up to âˆ’25% on â›”
    relax_blend_cross_suppress: float = 0.20  # trim crossâ€‘blend by â‰¤20%
    relax_blend_hold_boost: float     = 0.10  # boost holdâ€‘blend by â‰¤10%


# Internal FSM state
@dataclass
class _RungState:
    phase: ModePhase = "LOCKED"
    dwell: int = 0


# Humanâ€‘readable snapshot (handy for Studio/CLI)
@dataclass
class RungSnapshot:
    intent: str
    k_target: Optional[int]
    phase: ModePhase
    dwell: int
    delta: float
    band: float
    plan: Optional[Dict[str, Any]]
    relax: Optional[Dict[str, float]] = None  # {'calm': 0..1}

    def as_dict(self) -> Dict[str, Any]:
        return asdict(self)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Controller
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class RungController:
    """
    Nonâ€‘intrusive rung control that blends tiny overrides onto the Supervisor.

    Typical use in a training loop:
        ctrl_sup = sup.update(tele)                # Supervisor (baseline policy)
        ctrl_out = rung.update(tele, ctrl_sup)     # small rungâ€‘aware nudge
        model.apply_control(**ctrl_out)

    Arguments
    ---------
    delta: float
        Î´â‹† â€” the nominal rung spacing in the hidden log variable X.
    k_target: Optional[int]
        Target rung index for SEEK/HOLD strategies; ignored for STABILIZE.
    band: Optional[float]
        Acceptance halfâ€‘band in X. If None, uses epsilon_scale * Î´â‹†.
    intent: RungIntent | str
        "stabilize" | "hold" | "seek". Default: STABILIZE.
    tuning: Optional[RungTuning]
        Tunable safe defaults for blending and rails.

    Compatibility
    -------------
    This controller understands legacy â€œrelative stepâ€ requests via set_intent:
        set_intent("step_up", steps=2)     # seek up by +2 rungs
        set_intent("step_down", steps=1)   # seek down by âˆ’1 rung
    These are converted into a *pending plan* that is resolved on the next
    update() once the current rung k_now is observable.
    """

    # â€”â€”â€” construction â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

    def __init__(self,
                 delta: float,
                 k_target: Optional[int] = None,
                 band: Optional[float] = None,
                 intent: Union[RungIntent, str, None] = None,
                 tuning: Optional[RungTuning] = None):
        self.delta = float(delta)
        self.k_target = k_target
        self.band = band  # absolute band in X; if None, derive from epsilon_scale
        self.intent = self._as_intent(intent)
        self.tuning = tuning or RungTuning()
        self.state = _RungState()
        # Pending relative step plan, e.g. {"dir": +1, "steps": 2, "armed": True}
        self._plan: Optional[Dict[str, Any]] = None
        # Last computed relaxation calmness snapshot
        self._last_calm: Optional[float] = None

    # â€”â€”â€” public API â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

    def set_intent(self,
                   intent: Union[RungIntent, str],
                   k_target: Optional[int] = None,
                   *,
                   steps: Optional[int] = None,
                   direction: Optional[int] = None) -> None:
        """
        Set highâ€‘level intent. Backâ€‘compatible with â€œstep_up/downâ€ + steps=N.

        Examples
        --------
        set_intent("hold")
        set_intent(RungIntent.SEEK, k_target=7)
        set_intent("step_up", steps=2)      # â† legacy CLI path (resonator)
        set_intent("step_down", steps=1)    # â† legacy CLI path (resonator)
        """
        # Normalize
        if isinstance(intent, str):
            key = intent.lower().strip().replace("-", "_").replace(" ", "_")
        else:
            key = intent.value

        # Handle legacy relative steps explicitly
        if key in {"step_up", "up", "seek_up"} or (key == "seek" and direction in {+1}):
            n = max(int(steps or 1), 1)
            self._arm_relative_plan(dirn=+1, steps=n)
            self.intent = RungIntent.SEEK
            # absolute k_target (if provided) overrides the relative plan
            if k_target is not None:
                self.k_target = int(k_target)
                self._plan = None
            self._reset_fsm()
            return

        if key in {"step_down", "down", "seek_down"} or (key == "seek" and direction in {-1}):
            n = max(int(steps or 1), 1)
            self._arm_relative_plan(dirn=-1, steps=n)
            self.intent = RungIntent.SEEK
            if k_target is not None:
                self.k_target = int(k_target)
                self._plan = None
            self._reset_fsm()
            return

        # Standard intents
        self.intent = self._as_intent(key)
        if k_target is not None:
            self.k_target = int(k_target)
        self._reset_fsm()

    def clear(self) -> None:
        """Return to STABILIZE; reset state and clear plans."""
        self.intent = RungIntent.STABILIZE
        self.k_target = None
        self._plan = None
        self._reset_fsm()

    def status(self) -> Dict[str, object]:
        """Tiny JSONâ€‘like snapshot (handy to print in Studio)."""
        snap = RungSnapshot(
            intent=self.intent.value,
            k_target=self.k_target,
            phase=self.state.phase,
            dwell=self.state.dwell,
            delta=self.delta,
            band=self._epsilon(),
            plan=(dict(self._plan) if self._plan else None),
            relax=(None if self._last_calm is None else {"calm": float(self._last_calm)}),
        )
        return snap.as_dict()

    # Convenience wrappers (optional)
    def hold(self) -> None:
        self.set_intent(RungIntent.HOLD)

    def seek_to(self, k: int) -> None:
        self.set_intent(RungIntent.SEEK, k_target=int(k))

    def step_up(self, n: int = 1) -> None:
        self.set_intent("step_up", steps=n)

    def step_down(self, n: int = 1) -> None:
        self.set_intent("step_down", steps=n)

    # â€”â€”â€” main hook â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

    def update(self,
               tele: Dict[str, float],
               ctrl_from_supervisor: Optional[Dict[str, float]] = None
               ) -> Dict[str, float]:
        """
        Called once per training/inference step.

        Telemetry keys (bestâ€‘effort; all optional):
          'delta'|'Î´â‹†'          â€” current Î´â‹† (if Supervisor changes it)
          'kappa'|'Îº'           â€” lock confidence (0..1)
          'p_half'|'pÂ½'         â€” barrier probability (~0.5 near ridge)
          'x_mean'              â€” mean position in X (enables precise k detection)

        Relaxation / diffusion (all optional; ignored if absent):
          'folds'|'F'|'ð”‰'       â€” cumulative folds ð”‰ along the path/epoch
          'eta'|'Î·'             â€” share rate per unit path (higher â‡’ more active)
          'lambda'|'Î»'          â€” local lettingâ€‘go rate
          'D'                   â€” spatial smoothing strength

        ctrl_from_supervisor: existing dict with {beta, gamma, clamp}; if None,
        we start from {1.0, 0.5, 5.0} and blend toward our small targets.

        Returns a dict: {"beta": float, "gamma": float, "clamp": float}
        """
        # 0) Safe defaults
        ctrl = dict(ctrl_from_supervisor or {"beta": 1.0, "gamma": 0.5, "clamp": 5.0})

        # 1) Read telemetry (tolerant to missing keys)
        delta = float(tele.get("delta", tele.get("Î´â‹†", self.delta)))
        if delta != self.delta:
            self.delta = delta  # follow runtimeâ€™s Î´â‹† if it changes

        kappa = float(tele.get("kappa", tele.get("Îº", 0.0)))
        p_half = tele.get("p_half", tele.get("pÂ½", None))
        x_mean = tele.get("x_mean", None)

        # Optional relaxation inputs â†’ calmness âˆˆ [0,1]
        calm = self._relaxation_calm(tele)
        self._last_calm = calm

        # Infer current rung index & residual if possible
        k_now, r = None, None
        if x_mean is not None:
            k_now = self._nearest_k(float(x_mean))
            r = float(x_mean) - k_now * self.delta

        # 2) If there is a pending relative plan, resolve it to an absolute k_target
        if self._plan and self._plan.get("armed") and k_now is not None:
            # â€œseek N steps in dirâ€ â†’ absolute target
            dirn = int(self._plan.get("dir", 0))
            steps = int(self._plan.get("steps", 0))
            if dirn != 0 and steps > 0:
                self.k_target = k_now + dirn * steps
                self.intent = RungIntent.SEEK
            self._plan = None  # clear plan once translated

        # 3) Policy selection
        if self.intent == RungIntent.STABILIZE:
            # Keep within acceptance band; increase damping near barriers.
            target = self._target_stabilize(p_half=p_half)
            target = self._apply_relaxation(target, calm, phase=self.state.phase)
            w = self._relax_blend_weight(self.tuning.blend_hold, calm, phase="LOCKED")
            return self._blend(ctrl, target, w)

        if self.intent == RungIntent.HOLD:
            # Gently center on the nearest rung and keep it quiet.
            target = self._target_hold(p_half=p_half)
            target = self._apply_relaxation(target, calm, phase=self.state.phase)
            w = self._relax_blend_weight(self.tuning.blend_hold, calm, phase="LOCKED")
            return self._blend(ctrl, target, w)

        if self.intent == RungIntent.SEEK:
            # Walk toward a target rung; if missing, fall back to HOLD.
            if self.k_target is None or k_now is None:
                target = self._target_hold(p_half=p_half)
                target = self._apply_relaxation(target, calm, phase="LOCKED")
                w = self._relax_blend_weight(self.tuning.blend_hold, calm, phase="LOCKED")
                return self._blend(ctrl, target, w)

            # Direction toward target (+1 up, âˆ’1 down, 0 at target)
            dirn = 0
            if self.k_target > k_now:
                dirn = +1
            elif self.k_target < k_now:
                dirn = -1

            target, completed = self._target_step(direction=dirn, p_half=p_half, r=r, kappa=kappa)
            target = self._apply_relaxation(target, calm, phase=self.state.phase)
            w0 = target.pop("_blend", self.tuning.blend_cross)
            w = self._relax_blend_weight(w0, calm, phase=self.state.phase)
            out = self._blend(ctrl, target, w)

            # If we finished capturing a rung:
            if completed:
                # Are we at the absolute target? (Reâ€‘compute with the latest k_now if available)
                if x_mean is not None:
                    k_now_after = self._nearest_k(float(x_mean))
                    if k_now_after == self.k_target:
                        # Switch to HOLD automatically at destination
                        self.intent = RungIntent.HOLD
                        self._reset_fsm()
                    else:
                        # Keep seeking: next barrier will be handled next tick
                        self.state.phase = "LOCKED"
                        self.state.dwell = 0
                else:
                    # Without x_mean, assume one rung progress; keep seeking if diff remains
                    self.state.phase = "LOCKED"
                    self.state.dwell = 0
            return out

        # Fallback: passâ€‘through
        return ctrl

    # â€”â€”â€” internal helpers â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

    @staticmethod
    def _as_intent(x: Union[str, RungIntent, None]) -> RungIntent:
        if isinstance(x, RungIntent):
            return x
        if isinstance(x, str):
            key = x.lower().strip()
            for v in RungIntent:
                if v.value == key:
                    return v
        return RungIntent.STABILIZE

    def _reset_fsm(self) -> None:
        self.state = _RungState()

    def _arm_relative_plan(self, dirn: int, steps: int) -> None:
        """Record a â€˜relative stepâ€™ plan to be resolved on next update()."""
        self._plan = {"dir": int(dirn), "steps": int(steps), "armed": True}

    def _epsilon(self) -> float:
        """Acceptance halfâ€‘band in X."""
        if self.band is not None:
            return float(self.band)
        return self.tuning.epsilon_scale * self.delta

    def _nearest_k(self, x_mean: float) -> int:
        from math import floor
        # Round to nearest integer rung index
        return int(floor((x_mean / self.delta) + 0.5))

    def _clip(self, beta: float, gamma: float, clamp: float) -> Dict[str, float]:
        T = self.tuning
        b = min(max(beta, T.beta_min), T.beta_max)
        g = min(max(gamma, T.gamma_min), T.gamma_max)
        c = min(max(clamp, T.clamp_min), T.clamp_max)
        return {"beta": b, "gamma": g, "clamp": c}

    def _blend(self, base: Dict[str, float], target: Dict[str, float], w: float) -> Dict[str, float]:
        """Linear blend toward a safe target, then clip to rails."""
        w = float(min(max(w, 0.0), 1.0))
        beta = (1 - w) * base.get("beta", 1.0) + w * target.get("beta", 1.2)
        gamma = (1 - w) * base.get("gamma", 0.5) + w * target.get("gamma", 0.5)
        clamp = (1 - w) * base.get("clamp", 5.0) + w * target.get("clamp", 5.0)
        return self._clip(beta, gamma, clamp)

    # â€”â€”â€” policies â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

    def _target_stabilize(self, p_half: Optional[float]) -> Dict[str, float]:
        """
        Stabilize around rungs without forcing tight centering.

        Intuition
        ---------
        Closer to a barrier (pÂ½â‰ˆ0.5) â†’ keep damping higher; away â†’ moderate.
        """
        T = self.tuning
        if p_half is None:
            gamma = 0.5 * (T.gamma_damp_lo + T.gamma_damp_hi)
        else:
            # Map pÂ½ âˆˆ [0..1] to a â€œnearness to barrierâ€ score âˆˆ [0..1]
            d = abs(0.5 - float(p_half))
            nearness = 1.0 - min(max(d / 0.5, 0.0), 1.0)
            gamma = T.gamma_damp_lo + nearness * (T.gamma_damp_hi - T.gamma_damp_lo)
        return {"beta": T.beta_hold, "gamma": gamma, "clamp": T.clamp_safe}

    def _target_hold(self, p_half: Optional[float]) -> Dict[str, float]:
        """
        Sticky centering on the nearest rung:
          â€¢ slightly higher damping (Î³) to absorb chatter,
          â€¢ modest Î² to keep responsiveness,
          â€¢ clamp at a safe value.
        """
        T = self.tuning
        gamma = T.gamma_damp_hi if (p_half is None or p_half < 0.25) else 0.5 * (T.gamma_damp_lo + T.gamma_damp_hi)
        return {"beta": T.beta_hold, "gamma": gamma, "clamp": T.clamp_safe}

    def _target_step(self,
                     direction: int,
                     p_half: Optional[float],
                     r: Optional[float],
                     kappa: float) -> tuple[Dict[str, float], bool]:
        """
        Cross one barrier in the chosen direction, then reâ€‘lock.
        Returns: (target_control, completed: bool)

        completed=True means â€œwe have captured *a* rungâ€ (one step finished),
        not necessarily that weâ€™ve reached the absolute k_target. The caller
        continues seeking until k_now == k_target.
        """
        T = self.tuning

        # Decide via p_half if available; otherwise rely on r (residual) and Îº (confidence)
        at_mid = (p_half is not None and p_half >= 0.48) or (r is not None and abs(r) >= 0.45 * self.delta)
        well_locked = (p_half is not None and p_half <= T.p_half_lock) or (kappa >= 0.20)

        # FSM
        if self.state.phase == "LOCKED":
            if direction == 0:
                # Already at destination rung for this step
                return {"beta": T.beta_hold, "gamma": T.gamma_damp_hi, "clamp": T.clamp_safe, "_blend": T.blend_hold}, True
            # Start leaning toward the barrier in the chosen direction
            self.state.phase = "MID" if at_mid else "LOCKED"
            return {"beta": T.beta_boost, "gamma": T.gamma_damp_lo, "clamp": T.clamp_safe, "_blend": T.blend_cross}, False

        if self.state.phase == "MID":
            self.state.dwell += 1
            # If we can maintain MID a few ticks, weâ€™re safe to attempt crossing
            if self.state.dwell >= T.dwell_mid:
                self.state.phase = "CROSSING"
                self.state.dwell = 0
            # Keep nimble while staying around the barrier
            return {"beta": T.beta_boost, "gamma": T.gamma_damp_lo, "clamp": T.clamp_safe, "_blend": T.blend_cross}, False

        if self.state.phase == "CROSSING":
            # Watch for a sign that weâ€™ve gone over:
            crossed = False
            if p_half is not None:
                crossed = p_half >= T.p_half_target
            if (not crossed) and (r is not None):
                sign = 1 if direction > 0 else -1
                crossed = (sign * r) > 0  # residual sign matches push direction

            if crossed:
                self.state.phase = "CAPTURE"
                self.state.dwell = 0
                return {"beta": T.beta_hold, "gamma": T.gamma_damp_hi, "clamp": T.clamp_safe, "_blend": T.blend_capture}, False

            # Still crossing: stay nimble
            return {"beta": T.beta_boost, "gamma": T.gamma_damp_lo, "clamp": T.clamp_safe, "_blend": T.blend_cross}, False

        if self.state.phase == "CAPTURE":
            self.state.dwell += 1
            if self.state.dwell >= T.dwell_lock and well_locked:
                # Completed capture of one rung
                self.state.phase = "LOCKED"
                self.state.dwell = 0
                return {"beta": T.beta_hold, "gamma": T.gamma_damp_hi, "clamp": T.clamp_safe, "_blend": T.blend_hold}, True
            # Keep damping up during capture
            return {"beta": T.beta_hold, "gamma": T.gamma_damp_hi, "clamp": T.clamp_safe, "_blend": T.blend_capture}, False

        # Fallback (reset)
        self.state.phase = "LOCKED"
        self.state.dwell = 0
        return {"beta": T.beta_hold, "gamma": T.gamma_damp_hi, "clamp": T.clamp_safe, "_blend": T.blend_hold}, False

    # â€”â€”â€” relaxation helpers â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

    def _relaxation_calm(self, tele: Dict[str, Any]) -> float:
        """
        Turn optional diffusion/decay signals into a single calmness âˆˆ [0,1].

        Heuristics (monotone, bounded):
          â€¢ More folds ð”‰ or larger Î», D â†’ *more calm*.
          â€¢ Larger Î· (shareâ€‘rate now) â†’ *less calm*.
        """
        T = self.tuning

        def _get(keys: tuple[str, ...]) -> Optional[float]:
            for k in keys:
                if k in tele and tele[k] is not None:
                    try:
                        return float(tele[k])
                    except Exception:
                        pass
            return None

        def _squash_pos(x: Optional[float], scale: float) -> Optional[float]:
            if x is None or scale <= 0:
                return None
            v = abs(float(x))
            return v / (v + scale)

        F  = _get(("F", "ð”‰", "folds", "mathcalF", "mathcal_f"))
        eta = _get(("eta", "Î·"))
        lam = _get(("lambda", "Î»"))
        D   = _get(("D", "smooth", "smoothing"))

        parts: list[float] = []
        sF  = _squash_pos(F,   T.relax_F_scale)
        sL  = _squash_pos(lam, T.relax_lambda_scale)
        sD  = _squash_pos(D,   T.relax_D_scale)
        sE  = _squash_pos(eta, T.relax_eta_scale)

        if sF is not None: parts.append(sF)
        if sL is not None: parts.append(sL)
        if sD is not None: parts.append(sD)
        if sE is not None: parts.append(1.0 - sE)  # higher Î· â‡’ less calm

        if not parts:
            return 0.0
        calm = sum(parts) / len(parts)
        return float(max(0.0, min(1.0, calm)))

    def _apply_relaxation(self, target: Dict[str, float], calm: float, *, phase: ModePhase) -> Dict[str, float]:
        """Adjust {Î²,Î³,â›”} gently as calm â†‘. No effect if calmâ‰ˆ0."""
        if calm <= 0.0:
            return target
        T = self.tuning
        beta  = float(target.get("beta",  T.beta_hold))
        gamma = float(target.get("gamma", 0.5))
        clamp = float(target.get("clamp", T.clamp_safe))

        # Slightly soften Î² (less jumpy) â€” a bit stronger in LOCKED/CAPTURE
        beta_soft = T.relax_beta_soften * calm * (1.0 if phase in {"LOCKED", "CAPTURE"} else 0.5)
        beta = beta * (1.0 - beta_soft)

        # Slightly raise Î³ (more damping) â€” capped by rails later
        gamma = gamma + T.relax_gamma_boost * calm

        # Slightly soften clamp (smaller excursions)
        clamp = clamp * (1.0 - T.relax_clamp_soften * calm)

        out = dict(target)
        out.update({"beta": beta, "gamma": gamma, "clamp": clamp})
        return out

    def _relax_blend_weight(self, w: float, calm: float, *, phase: ModePhase | str) -> float:
        """Phaseâ€‘aware tweak of the blend weight with calmness."""
        if calm <= 0.0:
            return float(min(max(w, 0.0), 1.0))
        T = self.tuning
        if phase in {"MID", "CROSSING"}:
            w = w * (1.0 - T.relax_blend_cross_suppress * calm)
        else:  # LOCKED / CAPTURE / fallback
            w = w + (T.relax_blend_hold_boost * calm)
        return float(min(max(w, 0.0), 1.0))


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Null controller (noâ€‘op). Useful for tests / ablations.
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class NullRungController(RungController):
    """Passâ€‘through controller that never changes Supervisor outputs."""
    def __init__(self, delta: float, **_: Any) -> None:
        super().__init__(delta=delta)
        self.intent = RungIntent.STABILIZE

    def update(self, tele: Dict[str, float], ctrl_from_supervisor: Optional[Dict[str, float]] = None) -> Dict[str, float]:
        return dict(ctrl_from_supervisor or {"beta": 1.0, "gamma": 0.5, "clamp": 5.0})
